{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0gvMpOBFJil4"
   },
   "source": [
    "# Прикладная статистика. ДЗ 4.\n",
    "# Академия Аналитиков Авито\n",
    "\n",
    "\n",
    "__Правила:__\n",
    "- Жесткий дедлайн: **2022-03-27 17:59:59**. \n",
    "- Ответ и обсуждение решения — в телеграме.\n",
    "\n",
    "- Выполненную работу нужно отправить\n",
    "    - в чатик HW4-<ваше имя> через бота @AAA_stats23_bot\n",
    "- В качестве решения нужно отправить файл ipynb. Ссылка на интернет-ресурсы не принимается. Не публикуйте решения в открытом доступе!\n",
    "- Для выполнения задания используйте этот ноутбук в качествие основы, ничего не удаляя из него. **При этом можно добавлять новые ячейки!**\n",
    "- в ячейках с комменарием `#Автопроверка` нужно заполнить содержимое функций и классов (если есть), которые будут уже объявлены в этой ячейке. При этом:\n",
    "    - Нельзя убрирать или переставять `#Автопроверка` в ячейке. \n",
    "    - Нельзя менять сигнатуру и возвращаемое значение функций. То есть добавлять любой код можно, но удалять, что уже написано - нельзя.\n",
    "    - Нельзя ничего импортировать в таких ячейках. Все доступные для использования библиотеки будут указаны заранее. Такие слова, как `import`, `globals`, `locals`, `eval`, `exec` также нельзя использовать внутри ячеек.\n",
    "    - Нельзя использовать библиотеки, кроме тех, что указаны в задании. Ваш код должен работать именно с эти набором библиотек без любого дополнительного импорта!\n",
    "    - Нельзя использовать код из других ячеек ноутбука (кроме ячейки с импортом, в которой указаны все доступные библиотеки). Единственное исключение - если вы проставите в начало такой ячейки слово `#Автопроверка`. Тогда вы можете использовать код из этой ячейки.\n",
    "    - В случае нарушения этого правила автопроверка будет провалена и вы не получите часть баллов за задачу. \n",
    "    - В случае, если есть несколько ячеек автопроверки, то в каждой такой ячейке можно использовать созданные вами функции (или классы) из других ячеек автопроверки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xResAbODLSDZ"
   },
   "source": [
    "# 1 часть"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg0yqPWUJydC"
   },
   "source": [
    "## Задача 1 (3 балла)\n",
    "\n",
    "### На зачет (исправления)\n",
    "\n",
    "\n",
    "Пусть дана выборка из непрерывной случайной величины $\\xi$.\n",
    "Разработать односторонний аналог критерия Манна-Уитни для проверки\n",
    "гипотезы:\n",
    "- $H_0$: медиана случайной величины $\\xi$ равна m0\n",
    "- $H_1$: медиана случайной величины $\\xi$ больше m0\n",
    "\n",
    "Критические области статистики этого критерия нужно определить с помощью формулы, Монте-Карло процесс для их нахождения не допускается.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fcYSjZ70KZoe"
   },
   "source": [
    "Используемые библиотеки:\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats.binom import cdf\n",
    "from scipy.stats.norm import cdf\n",
    "from scipy.stats.t import cdf\n",
    "from scipy.stats.bernoulli import cdf\n",
    "```\n",
    "\n",
    "**При этом нельзя пользоваться функцией rvs!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gmczXn_fJZOt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nAqhrMCuKjmS"
   },
   "source": [
    "**Также, прежде чем приступить к написанию кода, распишите алгоритм и докажите корректность вашего критерия!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uRkyITZZKmNv"
   },
   "source": [
    "Гипотезы даны.\n",
    "\n",
    "Выберем статистику по аналогии со статистикой из Манн-Уитни: $$ U = \\sum [\\xi_i > \\mu_0] $$\n",
    "\n",
    "Поймем, как распределена статистика U. По сути, U - сумма бернуллевских случайных величин и значит U распределена биномиально. Для корректности критерия нужно потребовать $\\mathbb{P}_{H_0}(U > U_{кр}) \\leq \\alpha$. В гипотезе $H_0$ событие $[\\xi_i > \\mu_0]  $ срабатывает с вероятностью 1/2. Что понимать за критические значения? Альтернатива у нас то, что медиана больше, значит событие $[\\xi_i > \\mu_0]  $ срабатывает с меньшей вероятностью, поэтому мы должны брать pvalue как `binom.cdf(n=len(sample), p=0.5, x=U)`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cCbipbKmiT"
   },
   "source": [
    "Теперь переходите к реализации критерия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2SXpwK0WKhjC"
   },
   "outputs": [],
   "source": [
    "#Автопроверка\n",
    "\n",
    "MyMedianTestResults = namedtuple('MyMedianTestResults', \n",
    "                                  ['is_rejected', 'pvalue'])\n",
    "\n",
    "def median_test(sample: list, mu_0: float, alpha: float = 0.05):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "    - sample: текущая реализация выборки\n",
    "    - mu_0: медиана выборки при H_0\n",
    "    - alpha: уровень значимости критерия.\n",
    "        \n",
    "    Возвращает:\n",
    "    - MyMedianTestResults с полями:\n",
    "        - is_rejected: bool\n",
    "            - отверглась или нет гипотеза H_0 на уровне значимости alpha\n",
    "        - pvalue: float\n",
    "    \"\"\"\n",
    "\n",
    "    is_rejected = None\n",
    "    pvalue = None\n",
    "    sample = np.array(sample)\n",
    "    \n",
    "    U = sum(sample > mu_0)\n",
    "    pvalue = 1 - binom.cdf(n=len(sample), p=0.5, k=U)\n",
    "    \n",
    "    if pvalue < alpha:\n",
    "        is_rejected = True\n",
    "    else:\n",
    "        is_rejected = False\n",
    "\n",
    "    return MyMedianTestResults(is_rejected, pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0S3ADU8xJ6dk"
   },
   "source": [
    "Дополнительно: проверьте корректность вашего критерия) Здесь вы уже можете использовать любые библиотеки, какие вам нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Test Significance Level: 0.062, [0.049, 0.079]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "er = 0\n",
    "for _ in range(1000):\n",
    "    sample = norm.rvs(loc=8, scale=10, size=100)\n",
    "    mu_0 = norm.median(loc=8, scale=10)\n",
    "    if median_test(sample, mu_0).is_rejected:\n",
    "        er += 1\n",
    "\n",
    "left_level, right_level = proportion_confint(count = er, nobs = 1000, alpha=0.05, method='wilson')\n",
    "print(f\"Median Test Significance Level: {round(er/1000, 3)}, [{round(left_level, 3)}, {round(right_level, 3)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Test Significance Level: 0.067, [0.053, 0.084]\n"
     ]
    }
   ],
   "source": [
    "er = 0\n",
    "for _ in range(1000):\n",
    "    sample = t.rvs(df = 1, loc=8, scale=10, size=100)\n",
    "    mu_0 = t.median(df = 1, loc=8, scale=10)\n",
    "    if median_test(sample, mu_0).is_rejected:\n",
    "        er += 1\n",
    "\n",
    "left_level, right_level = proportion_confint(count = er, nobs = 1000, alpha=0.05, method='wilson')\n",
    "print(f\"Median Test Significance Level: {round(er/1000, 3)}, [{round(left_level, 3)}, {round(right_level, 3)}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка Монте-Карло вообще говоря для второго случая не проходит, но я думаю, с натяжкой можно считать, что критерий корректен."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CD3elLjyJ_hi"
   },
   "source": [
    "## Задача 2 (5 баллов)\n",
    "\n",
    "На занятии мы обсуждали, что криетрий Манна-Уитни (или логарифмирование метрики) часто применяют, чтобы не учитывать вклад от выбросов, которые портят результаты. Но мы также узнали, что это не лучший способ убирания выбросов, оба этих варианта легко ведут к неверным результатам.\n",
    "\n",
    "Но это не все методы, как справляются с выбросами в A/B-тесте. Иногда просто наиболее крупных пользователей просто выкидывают из теста. В этой задаче мы посмотрим на 2 таких метода.\n",
    "\n",
    "\n",
    "Для начала, давайте смоделируем искусственную задачу, на которой мы будем проверять критерии.\n",
    "\n",
    "- Представим, что ваша метрика в тесте и в контроле взята из экспоненциального распределения (например - выручка). `scale` - любой.\n",
    "- Пользователй в тесте и в контроле будет по 1000 человек.\n",
    "\n",
    "Далее полученные тестовые и контрольные выборки будут обозначаться как `test`, `control`.\n",
    "\n",
    "----\n",
    "**1 задача:** проверить, что для таких выборок можно использовать t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "J26MZGqyKF4T"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy.stats import expon, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0504, [0.04628220197159746, 0.05486308936331493]\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "assert expon.mean(loc=10, scale=6) == expon.mean(loc=5, scale=11)\n",
    "\n",
    "er = 0\n",
    "for _ in range(10000):\n",
    "    test = expon.rvs(loc=10, scale=6, size=size) \n",
    "    control = expon.rvs(loc=5, scale=11, size=size)\n",
    "    \n",
    "    pvalue = ttest_ind(control, test, alternative='two-sided').pvalue\n",
    "    if pvalue < 0.05:\n",
    "        er += 1\n",
    "\n",
    "l_b, r_b = proportion_confint(count = er, nobs = 10000, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f'{er/10000}, [{l_b}, {r_b}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, нормально :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6Kt4BadKKwQw"
   },
   "source": [
    "Теперь давайте перейдем к предлагаемым способам борьбы с выбросами. Для этого мы предлагаем следующие варианты: \n",
    "\n",
    "### Первый способ\n",
    "\n",
    "Подобрать квантиль для отсечения топ пользователей в тесте и в контроле, причем в каждом случае подобран свой порог. \n",
    "\n",
    "То есть, новый критерий состоит из 2 этапов:    \n",
    "1. Подобрать квантиль для отсечения в тесте и квантиль для отсечения в контроле.\n",
    "    - Например: \n",
    "    ```\n",
    "    outlier_control_filter = np.quantile(control, 0.99)\n",
    "    outlier_test_filter = np.quantile(test, 0.99)\n",
    "    \n",
    "    control = control[control < outlier_control_filter]\n",
    "    test    = test[test < outlier_test_filter]\n",
    "    ```\n",
    "2. Запустить на новых выборках t-test.\n",
    "\n",
    "Проверьте, корректный ли в таком случае будет критерий? Поясните полученный результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TNApVdUOKzk1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1301, [0.12364819512347855, 0.13683588687114798]\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "assert expon.mean(loc=10, scale=6) == expon.mean(loc=5, scale=11)\n",
    "\n",
    "er = 0\n",
    "for _ in range(10000):\n",
    "    test = expon.rvs(loc=10, scale=6, size=size) \n",
    "    control = expon.rvs(loc=5, scale=11, size=size)\n",
    "    \n",
    "    # Отсекаем\n",
    "    outlier_control_filter = np.quantile(control, 0.99)\n",
    "    outlier_test_filter = np.quantile(test, 0.99)\n",
    "\n",
    "    control = control[control < outlier_control_filter]\n",
    "    test    = test[test < outlier_test_filter]\n",
    "       \n",
    "    # Считаем pvalue    \n",
    "    pvalue = ttest_ind(control, test, alternative='two-sided').pvalue\n",
    "    if pvalue < 0.05:\n",
    "        er += 1\n",
    "\n",
    "l_b, r_b = proportion_confint(count = er, nobs = 10000, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f'{er/10000}, [{l_b}, {r_b}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, корректность критерий не проходит, так как рассчитанная ошибка очень отличается от заявленной.\n",
    "\n",
    "По моему мнению, так происходит, потому что после отсечения выборки уже другие и можно сказать, что каждая выборка \"поменяла\" свое распределение, из-за этого тест Монте-Карло просто неправильно работает. У нас были выборки с разными дисперсиями, следовательно мы отсекли выборки с разными весами, если так можно сказать"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "O8gudSEpK5KE"
   },
   "source": [
    "### Второй способ:\n",
    "\n",
    "1. Подобрать одну общую квантиль для отсечения в тесте и в контроле.\n",
    "    - Например: \n",
    "    ```\n",
    "    outlier_filter = np.quantile(np.concatenate([control, test]), 0.99)\n",
    "    \n",
    "    control = control[control < outlier_filter]\n",
    "    test    = test[test < outlier_filter]\n",
    "    ```\n",
    "2. Запустить на новых выборках t-test.\n",
    "\n",
    "#### 1 проверка\n",
    "\n",
    "Проверьте, корректный ли в таком случае будет критерий? Поясните полученный результат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Cn6RMDcSK7DW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5979, [0.5882540451949481, 0.6074707679240734]\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "assert expon.mean(loc=10, scale=6) == expon.mean(loc=5, scale=11)\n",
    "\n",
    "er = 0\n",
    "for _ in range(10000):\n",
    "    test = expon.rvs(loc=10, scale=6, size=size) \n",
    "    control = expon.rvs(loc=5, scale=11, size=size)\n",
    "    \n",
    "    # Отсекаем\n",
    "    outlier_filter = np.quantile(np.concatenate([control, test]), 0.99)\n",
    "\n",
    "    control = control[control < outlier_filter]\n",
    "    test    = test[test < outlier_filter]\n",
    "       \n",
    "    # Считаем pvalue    \n",
    "    pvalue = ttest_ind(control, test, alternative='two-sided').pvalue\n",
    "    if pvalue < 0.05:\n",
    "        er += 1\n",
    "\n",
    "l_b, r_b = proportion_confint(count = er, nobs = 10000, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f'{er/10000}, [{l_b}, {r_b}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По хорошему, конечно, нельзя сказать, что критерий корректен, так как рассчитанная ошибка все еще больше заявленной, но это уже намного лучше. \n",
    "\n",
    "Здесь мы одинаково учитываем выбросы с двух выборок."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vCX_cMphK8qi"
   },
   "source": [
    "#### 2 проверка\n",
    "\n",
    "Но и это еще не все. Теперь проверьте ваш критерий на симулированном A/B-тесте c эффектом, равным параметру `scale` в вашем распределении и проверьте гипотезу \n",
    "\n",
    "- $H_0: EA = EB$ + scale\n",
    "- $H_1: EA \\neq EB$ + scale\n",
    "\n",
    "Для этого добавьте к каждому элементу в выборке test параметр scale: \n",
    "```\n",
    "test = test + scale\n",
    "```\n",
    "\n",
    "1. Проверьте, что вы умеете с помощью ttest проверять заданную гипотезу. А точнее посмотрите, попадает ли в 95% процентах случаев в доверительный интервал истинный эффект `scale`?\n",
    "\n",
    "2. Работает ли в таком случае предложенный критерий убирания выбросов?\n",
    "\n",
    "3. Отличаются ли результаты у первой и у второй проверок? \n",
    "4. Сделайте вывод, можно ли использовать этот метод для убирания выбросов с точки зрения:\n",
    "    - Теории.\n",
    "    - Практики. Стали бы вы использовать в работе такой способ убирания выбросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "-H_uiF9EK-pG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049, [0.044939516707863926, 0.053406849822486356]\n"
     ]
    }
   ],
   "source": [
    "size=1000\n",
    "assert expon.mean(loc=10, scale=6) == expon.mean(loc=5, scale=11)\n",
    "\n",
    "er = 0\n",
    "for _ in range(10000):\n",
    "    test = expon.rvs(loc=10, scale=2, size=size) \n",
    "    control = expon.rvs(loc=10, scale=2, size=size)\n",
    "    \n",
    "    # Добавляем scale\n",
    "    test = test + 2\n",
    "       \n",
    "    # Считаем pvalue    \n",
    "    pvalue = ttest_ind(control, test, alternative='two-sided').pvalue\n",
    "    if pvalue < 0.05:\n",
    "        er += 1\n",
    "\n",
    "l_b, r_b = proportion_confint(count = er, nobs = 10000, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f'{er/10000}, [{l_b}, {r_b}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expon.var(loc=5, scale=6) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jrv-xfgBLb4E"
   },
   "source": [
    "# Часть 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "klpN-iSkLeTj"
   },
   "source": [
    "## Задача 3 (2 балла)\n",
    "\n",
    "### На зачет\n",
    "\n",
    "Пусть нам нужно оценить $\\mu$ — матожидание некой случайной величины, и у нас\n",
    "есть выборка из нее размером 1000. С помощью бутстрапа соберем 1000 бутстрап-выборок, для каждой посчитаем среднее, получим 1000 средних. Это выборка из\n",
    "1000 объектов, к ней можно применить критерий Стьюдента. Применим, построим\n",
    "доверительный интервал для 𝜇.\n",
    "\n",
    "Почему так делать нельзя?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wvC8tud1LA44"
   },
   "source": [
    "Мы никак не построим доверительный интервал именно для $\\mu$. Мы построим из выборки состоящей из оценок $\\hat\\mu$ только лишь доверительный интервал на среднее из этих оценок $\\hat\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma, sem\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = 6.0\n",
      "theta estim = 6.089\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "example_dist = gamma(a=2, scale=3)\n",
    "example_sample = example_dist.rvs(N)\n",
    "\n",
    "theta = example_dist.mean()\n",
    "theta_estim = np.mean(example_sample)\n",
    "\n",
    "print(f\"theta = {round(theta, 3)}\")\n",
    "print(f\"theta estim = {round(theta_estim, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estim_theta_sample(sample_len, gen_sample_func, theta_func, B=1000):\n",
    "    \"\"\"\n",
    "        Функция для генерации выборки theta estim.\n",
    "    \n",
    "        Праметры:\n",
    "            - sample_len: какого размера выборку надо генерировать. \n",
    "                - sample_len = len(sample)\n",
    "            - gen_sample_func: генерация выборки из нашего распределения, принимающая на вход лишь размер выборки. \n",
    "                - Например, gen_sample_func = lambda N: stats.norm().rvs(N)\n",
    "            - theta_func: функция генерации оценки theta по выборке.\n",
    "                - Например, lambda sample: numpy.percentile(sample, 75)\n",
    "            - B: сколько выборок надо сгенерировать, какого размера будет массив theta estim\n",
    "        Возвращает:\n",
    "            - Массив theta_estim_array размера B \n",
    "    \"\"\"\n",
    "    \n",
    "    theta_estim_array = []\n",
    "    for _ in range(B):\n",
    "        curr_sample = gen_sample_func(sample_len)\n",
    "        theta_estim = theta_func(curr_sample)\n",
    "        theta_estim_array.append(theta_estim)\n",
    "    return theta_estim_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff93dda6412f40969e6a0eac92d5aded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для оригинальной theta: 0.0%\n",
      "Для оценки theta: 95.39999999999999%\n"
     ]
    }
   ],
   "source": [
    "win_theta = 0\n",
    "win_theta_estim = 0\n",
    "for _ in tqdm(range(1000)):\n",
    "\n",
    "    gen_sample_func = lambda N: np.random.choice(example_sample, replace=True, size=N)\n",
    "\n",
    "    theta_func = lambda sample: np.mean(sample)\n",
    "\n",
    "    theta_estim_asterisk_array = get_estim_theta_sample(len(example_sample), gen_sample_func, theta_func, B=1000)\n",
    "    l, r = t.interval(alpha=0.95, loc=np.mean(theta_estim_asterisk_array), df=len(theta_estim_asterisk_array)-1, scale=sem(theta_estim_asterisk_array)) \n",
    "\n",
    "    if l < theta < r:\n",
    "        win_theta += 1\n",
    "    if l < theta_estim < r:\n",
    "        win_theta_estim += 1\n",
    "\n",
    "print(f'Для оригинальной theta: {round(win_theta/1000, 4)*100}%')\n",
    "print(f'Для оценки theta: {round(win_theta_estim/1000, 4)*100}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что и требовалось доказать :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CpRHZecLLqNl"
   },
   "source": [
    "## Задача 4 (3 балла)\n",
    "\n",
    "\n",
    "Пусть $X_1,\\ \\cdots, X_n$ &mdash; некоторая выборка и $X_1^*,\\ \\cdots, X_n^*$ &mdash; построенная по ней бутстрап-выборка.\n",
    "\n",
    "- С какой вероятностью элемент $X_i$ попадет в бутстрап-выборку?\n",
    "- Посчитайте среднее число уникальных элементов в бутстрап-выборке, если в исходной выборке все элементы различны."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FZh-O_0ANDgz"
   },
   "source": [
    "1) $$  \\mathbb{P} = \\frac{\\sum_j[X_j = X_i]}{n}$$\n",
    "\n",
    "2) $\\mathbb{E} = \\sum k*\\mathbb{P}($количество уникальных$ = k)$\n",
    "\n",
    "$\\mathbb{P}($количество уникальных$ = k) = ? $\n",
    "\n",
    "Способов выбрать k элементов из оригинальной выборки есть $C_n^k$.\n",
    "\n",
    "Способов разместить выбранные k элементов по бутстрап-выборке есть $A_n^k = \\frac{n!}{(n-k)!}$\n",
    "\n",
    "Вероятность реализации одного такого способа: $(\\frac{1}{n})^n$\n",
    "\n",
    "Таким образом, $$ \\mathbb{E} = \\sum k* \\frac{n!}{(n-k)!k!} * \\frac{n!}{(n-k)!} * \\frac{1}{n^n} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xLYkRd5cNEII"
   },
   "source": [
    "## Задача 5 (4 балла)\n",
    "\n",
    "### На зачет\n",
    "\n",
    "Пусть у вас выборка из неизвестного распределения (но все элементы больше 0) и вы хотите проверить гипотезу:\n",
    "$$\n",
    "\\begin{align}\n",
    "&H_0: E \\left[\\dfrac{median(X)}{\\overline{X}} \\right] = \\theta_0\\ vs.\\\\\n",
    "&H_1: E \\left[\\dfrac{median(X)}{\\overline{X}} \\right] \\neq \\theta_0\n",
    "\\end{align}\n",
    "$$\n",
    "* черточка означает среднее по выборке.\n",
    "\n",
    "С помощью бутстрапа постройте критерий уровня значимости $\\alpha$ для проверки этой гипотезы.\n",
    "\n",
    "Для этого вам надо:\n",
    "- Показать, в каких случаях вы отвергаете $H_0$\n",
    "- Как посчитать p-value.\n",
    "\n",
    "Для начала теоретически поясните ваш алгоритм действий."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CX7XhxSpNYdR"
   },
   "source": [
    "Формируем бутстрап-выборки и считаем для них `theta_func = = lambda sample: np.median(sample, axis=1)/np.mean(sample, axis=1)`\n",
    "\n",
    "Далее получаем выборку из оценок theta. Берем квантили: \n",
    "\n",
    "`left_theta_asterisk, right_theta_asterisk = np.quantile(theta_asterisk_array, [alpha/2, 1-alpha/2])`\n",
    "\n",
    "И если $\\theta_0 \\in $`[left_theta_asterisk, right_theta_asterisk]`, то нулевая гипотеза не отвергается.\n",
    "\n",
    "Далее я увидел, что еще нужно pvalue посчитать. Я выбрал такой путь: нам как-то надо получить распределение theta, чтобы сказать кто более экстремальный относительно полученной theta. У нас есть выборка, можно воспользоваться эмпирическим распределением. Итак, $$F_{emp}(\\theta_0) = \\frac{1}{n} \\cdot \\sum [\\theta_i < \\theta_0]$$\n",
    "\n",
    "Таким образом, $pvalue = 1- F_{emp}(\\theta_0)$. (Там еще некоторые модификации для двустороннего случая, они учтены в коде)\n",
    "\n",
    "В конце критерий проверен Монте-Карлом"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bu9cofHNbsP"
   },
   "source": [
    "Теперь перйдем к практике:\n",
    "\n",
    "Какими библиотеками вы можете пользоваться:\n",
    "```\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats.binom\n",
    "from scipy.stats.norm\n",
    "from scipy.stats.t\n",
    "from scipy.stats.bernoulli\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EwwCG-MBNb7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DpmsxdMLNpDz"
   },
   "source": [
    "**Чтобы код прошел автопроверку, используйте процентильный доверительный интервал!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "29uBzveyNdiT"
   },
   "outputs": [],
   "source": [
    "#Автопроверка\n",
    "\n",
    "MyStrangeStatResults = namedtuple('MyStrangeStatResults', \n",
    "                                  ['is_rejected', 'pvalue'])\n",
    "\n",
    "\n",
    "def bootstrap_strange_stat_checker(sample: list, mu_0: float, alpha: float = 0.05):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "    - sample: текущая реализация выборки\n",
    "    - mu_0: значение странной синусной статистики при H_0\n",
    "    - alpha: уровень значимости критерия.\n",
    "        \n",
    "    Возвращает:\n",
    "    - MyStrangeStatResults с полями:\n",
    "        - is_rejected: bool\n",
    "            - отверглась или нет гипотеза H_0 на уровне значимости alpha\n",
    "        - pvalue: float\n",
    "    \"\"\"\n",
    "    boot_samples_size = 1000\n",
    "    batch_size = boot_samples_size // 20\n",
    "    N = len(sample)\n",
    "    is_rejected = None\n",
    "    pvalue = None\n",
    "    theta_func = lambda sample: np.median(sample, axis=1)/np.mean(sample, axis=1)\n",
    "\n",
    "    #<Ваш код>\n",
    "    #Используйте процентильный доверительный интервал!\n",
    "    theta_estim = theta_func(np.expand_dims(sample, axis=0)).ravel()\n",
    "    assert len(theta_estim) == 1\n",
    "    theta_estim = theta_estim[0]\n",
    "    \n",
    "    theta_asterisk_array = []\n",
    "    for _ in range(0, boot_samples_size, batch_size):\n",
    "        bootstrap_sample = np.random.choice(sample, replace=True, size=(batch_size, N))\n",
    "        theta_asterisk = theta_func(bootstrap_sample).ravel()\n",
    "        assert len(theta_asterisk) == batch_size\n",
    "        theta_asterisk_array = np.concatenate([theta_asterisk_array, theta_asterisk])\n",
    "    left_theta_asterisk, right_theta_asterisk = np.quantile(theta_asterisk_array, [alpha/2, 1-alpha/2])\n",
    "    \n",
    "    F_mu0 = sum(theta_asterisk_array < mu_0)/len(theta_asterisk_array)\n",
    "    pvalue = 1 - F_mu0\n",
    "    if pvalue > 0.5:\n",
    "        pvalue = F_mu0\n",
    "    pvalue = pvalue * 2\n",
    "    \n",
    "    if left_theta_asterisk < mu_0 < right_theta_asterisk:\n",
    "        is_rejected = False\n",
    "    else:\n",
    "        is_rejected = True\n",
    "    \n",
    "\n",
    "    return MyStrangeStatResults(is_rejected, pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_D_o0zihN3PL"
   },
   "source": [
    "Теперь проверим на время ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UvuP0iMdN3gr"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6gDmjN0zN5P0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e532dc53174d4f8eeebdcfac24a5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Этот код на сервере академии должен выполняться не более 2 минут,\n",
    "# иначе он не пройдет проверку по времени\n",
    "for i in tqdm(range(1000)):\n",
    "    sample = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    bootstrap_strange_stat_checker(sample, mu_0=10, alpha=0.05)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим Монте_карлом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e536c94df8415999b646e9905f65fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042, CI = [0.031220885546165443, 0.05628442522660306]\n"
     ]
    }
   ],
   "source": [
    "bad_count = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    sample = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    mu_0 = sps.expon(loc=1, scale=1000).median()/sps.expon(loc=1, scale=1000).mean()\n",
    "    if bootstrap_strange_stat_checker(sample, mu_0=mu_0, alpha=0.05).is_rejected:\n",
    "        bad_count += 1\n",
    "l_b, r_b = proportion_confint(count = bad_count, nobs = 1000, alpha=0.05, method='wilson')\n",
    "print(f'{bad_count/1000}, CI = [{l_b}, {r_b}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, критерий корректен"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lBrR5UDvN7DN"
   },
   "source": [
    "## Задача 6 (2 балла)\n",
    "\n",
    "Эту задачу стоит решать только после второй задачи из домашки.\n",
    "\n",
    "Пусть мы подозреваем, что в AB-тесте в тестовой группе увеличилась дисперсия по сравнению с контрольной группой. Сформулировать это предположение на языке статистики и\n",
    "реализовать его проверку с помощью бутстрапа.\n",
    "\n",
    "**Ваши теоретические выкладки**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YC-aMUfNN_71"
   },
   "source": [
    "Сформулируем гипотезы. Наша оценка theta в данном случае есть выборочная дисперсия, и мы хотим проверить смещена ли оценка на тесте относительно контроля.\n",
    "\n",
    "$ H_0: \\mathbb{E}_{test}[\\frac{1}{n-1}\\sum(X_i - \\overline{X})^2] = \\mathbb{E}_{control}[\\frac{1}{n-1}\\sum(X_i - \\overline{X})^2]$\n",
    "\n",
    "$ H_1: \\mathbb{E}_{test}[\\frac{1}{n-1}\\sum(X_i - \\overline{X})^2] > \\mathbb{E}_{control}[\\frac{1}{n-1}\\sum(X_i - \\overline{X})^2] $\n",
    "\n",
    "Формируем две бутстрап-выборки, считаем для них выборочные дисперсии. Получим 2 выборки выборочных дисперсий для теста и контроля, далее считаем разницу этих выборок, берем перцентильный доверительный интервал (только односторонний, так как наша гипотеза односторонняя по условию) и есть ли там 0, то не нулевая гипотеза не отвергается. \n",
    "\n",
    "pvalue я считаю так же как и в прошлой задаче, через эмпирическое распределение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j5Hz-FkHODEw"
   },
   "source": [
    "Теперь перйдем к практике:\n",
    "\n",
    "Какими библиотеками вы можете пользоваться:\n",
    "```\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats.binom\n",
    "from scipy.stats.norm\n",
    "from scipy.stats.t\n",
    "from scipy.stats.bernoulli\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "iwYnOxcsODSS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wExgylYkOFJE"
   },
   "outputs": [],
   "source": [
    "#Автопроверка\n",
    "\n",
    "CompareVarianceResults = namedtuple('CompareVarianceResults', \n",
    "                                  ['is_rejected', 'pvalue'])\n",
    "\n",
    "\n",
    "def variance_ab_checker(control: list, test: list, alpha: float = 0.05):\n",
    "    \"\"\"\n",
    "    Параметры:\n",
    "    - control: контрольная группа\n",
    "    - test: тестовая группа\n",
    "    - alpha: уровень значимости критерия.\n",
    "        \n",
    "    Возвращает:\n",
    "    - CompareVarianceResults с полями:\n",
    "        - is_rejected: bool\n",
    "            - отверглась или нет гипотеза H_0 на уровне значимости alpha\n",
    "        - pvalue: float\n",
    "    \"\"\"\n",
    "    boot_samples_size = 1000\n",
    "    batch_size = boot_samples_size // 20\n",
    "    N_test = len(test)\n",
    "    N_control = len(control)\n",
    "    is_rejected = None\n",
    "    pvalue = None\n",
    "    left_bound = None\n",
    "    right_bound = None\n",
    "    theta_func = lambda sample: np.var(sample, ddof=1, axis=1)\n",
    "\n",
    "    theta_array = []\n",
    "    for _ in range(0, boot_samples_size, batch_size):\n",
    "        # Генерируем сразу batch_size выборок\n",
    "        bootstrap_test = np.random.choice(test, replace=True, size=(batch_size, N_test))\n",
    "        bootstrap_control = np.random.choice(control, replace=True, size=(batch_size, N_control))\n",
    "            \n",
    "        theta_test = theta_func(bootstrap_test).ravel()\n",
    "        theta_control = theta_func(bootstrap_control).ravel()\n",
    "        assert len(theta_test) == batch_size and len(theta_control) == batch_size\n",
    "        theta_array = np.concatenate([theta_array, theta_test - theta_control])\n",
    "    left_theta = np.quantile(theta_array, alpha)\n",
    "    if left_theta > 0:\n",
    "        is_rejected = True\n",
    "    else:\n",
    "        is_rejected = False\n",
    "    \n",
    "    pvalue = sum(theta_array < 0)/len(theta_array)\n",
    "\n",
    "\n",
    "    return CompareVarianceResults(is_rejected, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dp7apAUoONCL"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPviyX2vONa5"
   },
   "outputs": [],
   "source": [
    "# Этот код на сервере академии должен выполняться не более 10 минут,\n",
    "# иначе он не пройдет проверку по времени\n",
    "for i in tqdm(range(1000)):\n",
    "    test = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    control = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    variance_ab_checker(test, control, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d37e397b5b747cf97388a8eca75064e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059, CI = [0.04601429821280047, 0.07536090277145915]\n"
     ]
    }
   ],
   "source": [
    "bad_count = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    test = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    control = sps.expon(loc=1, scale=1000).rvs(1000)\n",
    "    if variance_ab_checker(test, control, alpha=0.05).is_rejected:\n",
    "        bad_count += 1\n",
    "l_b, r_b = proportion_confint(count = bad_count, nobs = 1000, alpha=0.05, method='wilson')\n",
    "print(f'{bad_count/1000}, CI = [{l_b}, {r_b}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
